{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports:\n",
    "from collections import OrderedDict #to remove duplicates\n",
    "import pandas as pd #dataframes\n",
    "import numpy as np #np matrices\n",
    "from sklearn import preprocessing #label encoding\n",
    "from sklearn.feature_extraction.text import CountVectorizer #text transformation\n",
    "from sklearn.naive_bayes import GaussianNB #naive Bayes classifier\n",
    "from sklearn.model_selection import cross_val_score #cross validation scores\n",
    "\n",
    "#define helper functions\n",
    "def transformDate(x):\n",
    "\treturn int(x.split('.')[2])*31*12+int(x.split('.')[1])*31+int(x.split('.')[0])\n",
    "\n",
    "def getDay(x):\n",
    "\treturn int(x.split('.')[0])\n",
    "\n",
    "def getYear(x):\n",
    "\treturn int(x.split('.')[2])\n",
    "\n",
    "def getMonth(x):\n",
    "\treturn int(x.split('.')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Auftragskonto Buchungstag Valutadatum              Buchungstext  \\\n",
      "0     89990201.0  28.07.2016  28.07.2016             Lohn / Gehalt   \n",
      "1     89990201.0  27.07.2016  27.07.2016                     Miete   \n",
      "2     89990201.0  21.07.2016  21.07.2016                   Bargeld   \n",
      "3     89990201.0  20.07.2016  20.07.2016  Lebensmittel / Getraenke   \n",
      "4     89990201.0  18.07.2016  18.07.2016            Spontanausgabe   \n",
      "\n",
      "                                    Verwendungszweck  \\\n",
      "0  Gehalt Adorsys GmbH & Co. KG End-To-End-Ref.: ...   \n",
      "1  Byladem1Sbt De12773501123456789889 Miete Beuth...   \n",
      "2  21.07/16.34Uhr Nuernberg All Eur 70,00 Geb.Eur...   \n",
      "3  2831 Edeka Neubauer Nuernb.//Nuernb 2016-07-20...   \n",
      "4                                             Amazon   \n",
      "\n",
      "  Beguenstigter/Zahlungspflichtiger             Kontonummer          BLZ  \\\n",
      "0             Adorsys GmbH & Co. KG              7807800780     25190001   \n",
      "1                      Georg Tasche  DE31251900019123456780  VOHADE2HXXX   \n",
      "2                           Bargeld              9999900780     25190001   \n",
      "3                     Kartenzahlung              9736000780     25190001   \n",
      "4                  neue Playstation              9988776655     25125100   \n",
      "\n",
      "    Betrag Waehrung             label  \n",
      "0  2000.00      EUR            income  \n",
      "1  -670.00      EUR            living  \n",
      "2   -70.00      EUR           private  \n",
      "3   -73.21      EUR  standardOfLiving  \n",
      "4     -363      EUR           leisure  \n"
     ]
    }
   ],
   "source": [
    "#read in the csv file using pandas\n",
    "#read file and create dataset, seperators are semicolons\n",
    "dataset=pd.read_csv(\"ex1dataset.csv\",sep=';',engine='python')\n",
    "#drop the 'Unnamed: 0' column as this is only the line number\n",
    "dataset.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "#explore dataset\n",
    "print(dataset.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "finance             33\n",
      "income              17\n",
      "leisure             65\n",
      "living              26\n",
      "private             21\n",
      "standardOfLiving    47\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#create a copy of the dataset for analysis\n",
    "analysisSet=pd.read_csv(\"ex1dataset.csv\",sep=';',engine='python')\n",
    "analysisSet.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "\n",
    "#group set by label and print number of entries per label\n",
    "print(analysisSet.groupby('label').agg('size'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Auftragskonto                      Buchungstag             \\\n",
      "                          mean       std nunique           mean        std   \n",
      "label                                                                        \n",
      "finance               0.696970  0.728219       3  750084.666667  50.195036   \n",
      "income                0.823529  0.808957       3  750087.882353  58.687608   \n",
      "leisure               1.969231  0.248069       2  750037.784615  33.691844   \n",
      "living                1.346154  0.845804       3  750068.153846  53.385910   \n",
      "private               1.333333  0.856349       3  750076.904762  55.655103   \n",
      "standardOfLiving      1.127660  0.849988       3  750094.085106  51.385512   \n",
      "\n",
      "                            Valutadatum                    Buchungstext  ...  \\\n",
      "                 nunique           mean        std nunique         mean  ...   \n",
      "label                                                                    ...   \n",
      "finance               19  750084.666667  50.195036      19     8.575758  ...   \n",
      "income                 8  750087.882353  58.687608       8     9.058824  ...   \n",
      "leisure               42  750037.800000  33.686143      42     7.846154  ...   \n",
      "living                19  750068.153846  53.385910      19     8.961538  ...   \n",
      "private               15  750076.904762  55.655103      15     2.047619  ...   \n",
      "standardOfLiving      31  750094.085106  51.385512      31     6.914894  ...   \n",
      "\n",
      "                 Waehrung        Day                        Month            \\\n",
      "                  nunique       mean        std nunique      mean       std   \n",
      "label                                                                         \n",
      "finance                 1  12.424242   9.463847      10  3.878788  1.634732   \n",
      "income                  1  28.294118   1.447615       5  3.470588  1.874755   \n",
      "leisure                 1  14.246154   9.024326      25  2.307692  1.130861   \n",
      "living                  1  18.384615   9.616972      13  3.153846  1.566967   \n",
      "private                 1  14.190476  11.910580      10  3.571429  1.938335   \n",
      "standardOfLiving        1  10.829787   8.498898      21  4.234043  1.759604   \n",
      "\n",
      "                          Year               \n",
      "                 nunique  mean  std nunique  \n",
      "label                                        \n",
      "finance                7  2016  0.0       1  \n",
      "income                 7  2016  0.0       1  \n",
      "leisure                5  2016  0.0       1  \n",
      "living                 7  2016  0.0       1  \n",
      "private                6  2016  0.0       1  \n",
      "standardOfLiving       7  2016  0.0       1  \n",
      "\n",
      "[6 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "#analyse the impact of the features on the label\n",
    "\n",
    "#convert 'Betrag' to float and replace commas by dots before\n",
    "analysisSet['Betrag']=analysisSet['Betrag'].str.replace(',','.')\n",
    "analysisSet['Betrag']=analysisSet['Betrag'].astype(float)\n",
    "\n",
    "#fill NaN entries in 'Auftragskonto' by mean value of other columns\n",
    "analysisSet['Auftragskonto']=analysisSet['Auftragskonto'].astype(float)\n",
    "analysisSet['Auftragskonto'].fillna(analysisSet['Auftragskonto'].mean(),inplace=True)\n",
    "analysisSet['Auftragskonto']=analysisSet['Auftragskonto'].astype(int)\n",
    "\n",
    "#set all other columns as string entries\n",
    "analysisSet['Kontonummer']=analysisSet['Kontonummer'].astype(str)\n",
    "analysisSet['BLZ']=analysisSet['BLZ'].astype(str)\n",
    "analysisSet['Buchungstag']=analysisSet['Buchungstag'].astype(str)\n",
    "analysisSet['Valutadatum']=analysisSet['Valutadatum'].astype(str)\n",
    "\n",
    "analysisSet['Day']=analysisSet['Buchungstag'].astype(str)\n",
    "analysisSet['Day']=analysisSet['Day'].apply(lambda x: getDay(x))\n",
    "analysisSet['Month']=analysisSet['Buchungstag'].astype(str)\n",
    "analysisSet['Month']=analysisSet['Month'].apply(lambda x: getMonth(x))\n",
    "analysisSet['Year']=analysisSet['Buchungstag'].astype(str)\n",
    "analysisSet['Year']=analysisSet['Year'].apply(lambda x: getYear(x))\n",
    "\n",
    "#transform Dates to numbers\n",
    "analysisSet['Buchungstag']=dataset['Buchungstag'].apply(lambda x: transformDate(x))\n",
    "analysisSet['Valutadatum']=dataset['Valutadatum'].apply(lambda x: transformDate(x))\n",
    "analysisSet['Buchungstag']=analysisSet['Buchungstag'].astype(int)\n",
    "analysisSet['Valutadatum']=analysisSet['Valutadatum'].astype(int)\n",
    "\n",
    "#convert all string columns to numbers with the use of the label encoder\n",
    "le=preprocessing.LabelEncoder()\n",
    "for entry in ['Auftragskonto','Buchungstext',\n",
    "'Verwendungszweck','Beguenstigter/Zahlungspflichtiger','Waehrung']:\n",
    "\tanalysisSet[entry]=le.fit_transform(analysisSet[entry])\n",
    "    \n",
    "#group the set by labels and print the number of different values, the mean and the stddev for each column\n",
    "print(analysisSet.groupby('label').agg(['mean','std','nunique']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Buchungstext  \\\n",
      "0             Lohn / Gehalt   \n",
      "1                     Miete   \n",
      "2                   Bargeld   \n",
      "3  Lebensmittel / Getraenke   \n",
      "4            Spontanausgabe   \n",
      "\n",
      "                                    Verwendungszweck  \\\n",
      "0  Gehalt Adorsys GmbH & Co. KG End-To-End-Ref.: ...   \n",
      "1  Byladem1Sbt De12773501123456789889 Miete Beuth...   \n",
      "2  21.07/16.34Uhr Nuernberg All Eur 70,00 Geb.Eur...   \n",
      "3  2831 Edeka Neubauer Nuernb.//Nuernb 2016-07-20...   \n",
      "4                                             Amazon   \n",
      "\n",
      "  Beguenstigter/Zahlungspflichtiger   Betrag             label  Day  \n",
      "0             Adorsys GmbH & Co. KG  2000.00            income   28  \n",
      "1                      Georg Tasche  -670.00            living   27  \n",
      "2                           Bargeld   -70.00           private   21  \n",
      "3                     Kartenzahlung   -73.21  standardOfLiving   20  \n",
      "4                  neue Playstation     -363           leisure   18  \n"
     ]
    }
   ],
   "source": [
    "#clean out the dataset based on the revalations of the analysis\n",
    "\n",
    "#keep day for use later on as maybe there might be covariance between day and \n",
    "dataset['Day']=dataset['Buchungstag'].apply(lambda x: getDay(x))\n",
    "dataset['Day']=dataset['Day'].astype(int)\n",
    "#Waehrung: Analysis showed only one unique value so there is no gain in keeping it for classification\n",
    "#Kontonummer,Auftagskonto,BLZ: numbers that were assigned to the associated accounts likely not correlate to the kind of transaction.\n",
    "#(Analysis also showed little to no difference between the different labels)\n",
    "#Buchungstag,Valutdatum: assumption that the date of a purchase does not correlate with the class of transaction we are trying to predict\n",
    "#(The analysis does not quite support that assumption but I'm still holding on to that assumption :D)\n",
    "dataset.drop(['Waehrung','Kontonummer','Auftragskonto','Buchungstag','Valutadatum','BLZ'],axis=1,inplace=True)\n",
    "#explore the reduced dataset\n",
    "print(dataset.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Betrag  label  Day                                               Text\n",
      "0  2000.00      1   28  Lohn Gehalt Adorsys GmbH Co KG End-To-End-Ref ...\n",
      "1  -670.00      3   27  Miete Beuthener Str End-To-End-Ref Notprovided...\n",
      "2   -70.00      4   21  Bargeld Nuernberg All Eur Geb Einzahlung Ausza...\n",
      "3   -73.21      5   20  Lebensmittel Getraenke Edeka Neubauer Nuernb -...\n",
      "4  -363.00      2   18             Spontanausgabe Amazon neue Playstation\n"
     ]
    }
   ],
   "source": [
    "#treat the data to make it suitable for a skit.learn classifier\n",
    "\n",
    "#remove special characters from 'Buchungstext','Vetwendungszweck' and 'Beguenstigter/Zahlungspflichtuger'\n",
    "for label in ['Buchungstext','Verwendungszweck','Beguenstigter/Zahlungspflichtiger']:\n",
    "\tdataset[label]=dataset[label].str.replace('/',' ')\n",
    "\tdataset[label]=dataset[label].str.replace('(',' ')\n",
    "\tdataset[label]=dataset[label].str.replace(')',' ')\n",
    "\tdataset[label]=dataset[label].str.replace(':',' ')\n",
    "\tdataset[label]=dataset[label].str.replace('.',' ')\n",
    "\tdataset[label]=dataset[label].str.replace('&',' ')\n",
    "\tdataset[label]=dataset[label].str.replace(',',' ')\n",
    "    \n",
    "    \n",
    "#join the three colomns 'Buchungstext','Verwendungszweck' and 'Beguenstigter/Zahlungspflichtiger'\n",
    "#(this is to combat the fact that these columns are intermixed a lot depending on the data source)\n",
    "dataset['Text']=dataset[['Buchungstext','Verwendungszweck','Beguenstigter/Zahlungspflichtiger']].agg(\" \".join,axis=1)\n",
    "#drop the original columns\n",
    "dataset.drop(['Buchungstext','Verwendungszweck','Beguenstigter/Zahlungspflichtiger'],axis=1,inplace=True)\n",
    "\n",
    "#remove all entries in 'Text' that contain numbers as they likely belong to information that is not necessary for prediction (Times, Account numbers, Dates, Postal Codes) or redundant Values (Transaction values) and only affect few useful pieces\n",
    "dataset['Text']=dataset['Text'].str.replace(r'\\w*\\d\\w*','',regex=True)\n",
    "#remove duplicate words in 'Text'\n",
    "dataset['Text']=dataset['Text'].str.split().apply(lambda x: OrderedDict.fromkeys(x).keys()).str.join(' ')\n",
    "\n",
    "#replace all commas in 'Betrag' by dots to keep the encoding consistent\n",
    "dataset['Betrag']=dataset['Betrag'].str.replace(',','.')\n",
    "#convert 'Betrag' entries to numerical values\n",
    "dataset['Betrag']=dataset['Betrag'].astype(float)\n",
    "#convert labels to numerical data\n",
    "le=preprocessing.LabelEncoder()\n",
    "dataset['label']=le.fit_transform(dataset['label'])\n",
    "\n",
    "#explore the treated dataset\n",
    "print(dataset.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.00e+03  0.00e+00  0.00e+00 ...  0.00e+00  0.00e+00  0.00e+00]\n",
      " [-6.70e+02  0.00e+00  0.00e+00 ...  0.00e+00  0.00e+00  0.00e+00]\n",
      " [-7.00e+01  0.00e+00  0.00e+00 ...  0.00e+00  0.00e+00  0.00e+00]\n",
      " ...\n",
      " [ 2.00e+03  0.00e+00  0.00e+00 ...  0.00e+00  0.00e+00  0.00e+00]\n",
      " [-4.00e+03  0.00e+00  0.00e+00 ...  0.00e+00  0.00e+00  0.00e+00]\n",
      " [-5.12e+01  1.00e+00  0.00e+00 ...  0.00e+00  0.00e+00  0.00e+00]]\n",
      "0      1\n",
      "1      3\n",
      "2      4\n",
      "3      5\n",
      "4      2\n",
      "      ..\n",
      "204    0\n",
      "205    0\n",
      "206    1\n",
      "207    0\n",
      "208    2\n",
      "Name: label, Length: 209, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#encode the string feature to a bag of words using CountVectorizer\n",
    "cv=CountVectorizer()\n",
    "cv.fit(dataset['Text'])\n",
    "Text_tranformed=cv.transform(dataset['Text']).todense()\n",
    "#split labels from dataset and keep colume as Y values and Rest as X values\n",
    "Y_vals=dataset['label']\n",
    "X_vals=np.hstack((dataset['Betrag'].values.reshape(len(dataset['Betrag']),1),Text_tranformed))\n",
    "\n",
    "print(X_vals)\n",
    "print(Y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.80e+01  2.00e+03  0.00e+00 ...  0.00e+00  0.00e+00  0.00e+00]\n",
      " [ 2.70e+01 -6.70e+02  0.00e+00 ...  0.00e+00  0.00e+00  0.00e+00]\n",
      " [ 2.10e+01 -7.00e+01  0.00e+00 ...  0.00e+00  0.00e+00  0.00e+00]\n",
      " ...\n",
      " [ 2.80e+01  2.00e+03  0.00e+00 ...  0.00e+00  0.00e+00  0.00e+00]\n",
      " [ 2.80e+01 -4.00e+03  0.00e+00 ...  0.00e+00  0.00e+00  0.00e+00]\n",
      " [ 8.00e+00 -5.12e+01  1.00e+00 ...  0.00e+00  0.00e+00  0.00e+00]]\n"
     ]
    }
   ],
   "source": [
    "#lets add day to the feature matrix\n",
    "X_vals=np.hstack((dataset['Day'].values.reshape(len(dataset['Day']),1),X_vals))\n",
    "print(X_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.8902439024390244 var: 0.08035370016766939\n"
     ]
    }
   ],
   "source": [
    "#train and score a gaussian naive bayes classifier\n",
    "gnb= GaussianNB()\n",
    "scores=cross_val_score(gnb,X_vals,Y_vals,cv=5)\n",
    "print(\"mean: \"+str(scores.mean())+\" var: \"+str(scores.std()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
